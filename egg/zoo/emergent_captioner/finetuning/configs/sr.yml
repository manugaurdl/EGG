DEBUG : True
INIT_VAL : True
GREEDY_BASELINE : False
SAVE_BEST_METRIC : True # to save nothing : = False and checkpoint_freq = 0
captions_type : "coco" #coco, (mistral, mistral_4), blip_holistic
train_method : "discriminative" # (discriminative, cider, mle)
prefix_len : 10
warmup_ratio : 0.034
official_clipcap_weights : /home/manugaur/official_clipcap/coco_weights.pt
num_workers : 16
CAPS_PER_IMG_train: 4
CAPS_PER_IMG_val: 4

opts: 
  baseline : mean
  n_epochs : 1
  batch_size : 100
  lr :  1e-7 #2e-5
  max_len : 50
  checkpoint_freq : 0
  num_workers : 16
  dataset_dir : /home/manugaur/coco
  mle_model_path : /home/manugaur/EGG/checkpoints/blip2mistral/mle/best.pt # mistral_4 , coco
  checkpoint_dir : /home/manugaur/EGG/checkpoints/blip2mistral/sr
    
WANDB :
  logging : False
  sweep : False
  sweep_id: ""
  sweep_run_count : 100
  entity : "manugaur"
  project : "emergent_captioner"
  run_name : "sr_len_50_lr_1e-7_bs_100_blip2mistral"

inference : 
  batch_size : 180
  output_dir : /home/manugaur/EGG/inference_preds/

#debug, init_val, logging, bsz, lr